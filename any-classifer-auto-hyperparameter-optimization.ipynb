{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This an automated pipeline hyperparameter optimization search for any classification algorithms in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "df = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\n",
    "    'sepal length':df.data[:,0],\n",
    "    'sepal width':df.data[:,1],\n",
    "    'petal length':df.data[:,2],\n",
    "    'petal width':df.data[:,3],\n",
    "    'species':df.target\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=df['species']  # Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarize data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# a simple pipeline for hyperparameter optimization of all the 5 different models\n",
    "# (could have wrote a more condense function )\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load and split the data, into 70/30 training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.simplefilter(action='ignore', category=DataConversionWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1. input cls_name(user defined)\n",
    "### step 2. input actual classifier name\n",
    "### step 3. specify corresponding hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameters grid search in process... \n",
      "\n",
      "Estimator: random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__criterion': 'entropy', 'clf__max_depth': 7, 'clf__min_samples_leaf': 25, 'clf__n_estimators': 20}\n",
      "Mean cross-validated score of the best_estimator: 0.524\n",
      "Test set accuracy score for best params: 0.867 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        18\n",
      "           1       1.00      0.57      0.73        14\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.87        45\n",
      "   macro avg       0.90      0.86      0.86        45\n",
      "weighted avg       0.89      0.87      0.86        45\n",
      "\n",
      "\n",
      "Estimator: logistic_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'clf__C': 5, 'clf__class_weight': 'balanced', 'clf__solver': 'lbfgs'}\n",
      "Mean cross-validated score of the best_estimator: 0.943\n",
      "Test set accuracy score for best params: 0.978 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "Estimator: support_vector\n",
      "Best params: {'clf__C': 1, 'clf__class_weight': None}\n",
      "Mean cross-validated score of the best_estimator: 0.943\n",
      "Test set accuracy score for best params: 0.978 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 1. assign a name to the classifier that you want to use\n",
    "cls_name = {0: 'random_forest', 1: 'logistic_regression', 2: 'support_vector'}\n",
    "\n",
    "# 2. assign the actual classifier name in sklearn\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC()\n",
    "    ]\n",
    "# 3. This is the manual part, specify the corresponding hyperparameters that you want to optimize, hyperparameters are different for each classifer in most cases. Be careful of conditional hyperparameters, you will get an error if not specified correctly\n",
    "parameters = [{'clf__criterion': ['gini', 'entropy'],\n",
    " 'clf__n_estimators': [20,30],\n",
    "'clf__min_samples_leaf': [25,50],\n",
    "'clf__max_depth': [3,4,5,6,7]},\n",
    "    \n",
    "{'clf__C': [0.001, 0.1, 1, 5],\n",
    "'clf__class_weight': [None,'balanced',{0:0.25, 1:0.75}],\n",
    "'clf__solver': ['lbfgs', 'liblinear']},\n",
    "    \n",
    "{'clf__C': [0.001, 0.1, 1, 5],\n",
    "'clf__class_weight': [None,'balanced']}\n",
    "]\n",
    "    \n",
    "# Fit the grid search objects\n",
    "print('hyperparameters grid search in process... ')\n",
    "\n",
    "\n",
    "#create a placehold for best accuracy and best model parameters, these place must be set within in the loop, not global.\n",
    "best_val_acc = 0\n",
    "best_val_clf = []\n",
    "best_val_gs = []\n",
    "    \n",
    "best_test_acc = 0\n",
    "best_test_clf = []\n",
    "best_test_gs = []\n",
    "\n",
    "# there are only 3 parameters to change, the name of the classifier, the actual classifer in sklearn and the corresponding hyperparameters\n",
    "for idx, classifier, params in zip(cls_name, classifiers, parameters):\n",
    "    \n",
    "    clf_pipe = Pipeline([\n",
    "        ('clf', classifier)\n",
    "        ])\n",
    "    gs_clf = GridSearchCV(clf_pipe, param_grid=params, n_jobs=-1)\n",
    "    \n",
    "    print('\\nEstimator: %s' % cls_name[idx])\n",
    "    # Fit grid search\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs_clf.best_params_)\n",
    "    # Best validation data accuracy\n",
    "    print('Mean cross-validated score of the best_estimator: %.3f' % gs_clf.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs_clf.predict(X_test)\n",
    "    # Test data accuracy of model with best params and print classification report\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    print (classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Track best validation accuracy model, default k=5 since v0.22\n",
    "    if gs_clf.best_score_ > best_val_acc:\n",
    "        best_val_acc = gs_clf.best_score_\n",
    "        best_val_gs = gs_clf\n",
    "        best_val_clf = cls_name[idx]\n",
    "    # Track best test accuracy model\n",
    "    if accuracy_score(y_test, y_pred) > best_test_acc:\n",
    "        best_test_acc = accuracy_score(y_test, y_pred)\n",
    "        best_test_gs = gs_clf\n",
    "        best_test_clf = cls_name[idx]\n",
    "    # note: Often the best validation is the also the best test accuracy model, however in rare instances that may not be the case. If the results of validation between two classifier are really close, then it can easily have a different best testing accuracy classifer. it's up to the data scientist to investigate further the most suitable model to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
